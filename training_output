model fitting - Bidirectional LSTM
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
headline_input (InputLayer)     (None, 10)           0                                            
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 20, 300)      8342400     headline_input[0][0]             
__________________________________________________________________________________________________
body_sent_input (InputLayer)    (None, None, 20)     0                                            
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) [(None, 256), (None, 439296      embedding_1[0][0]                
__________________________________________________________________________________________________
time_distributed_1 (TimeDistrib (None, None, 512)    9483136     body_sent_input[0][0]            
__________________________________________________________________________________________________
bidirectional_3 (Bidirectional) (None, 256)          656384      time_distributed_1[0][0]         
                                                                 bidirectional_1[0][1]            
                                                                 bidirectional_1[0][2]            
                                                                 bidirectional_1[0][3]            
                                                                 bidirectional_1[0][4]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 512)          0           bidirectional_1[0][0]            
                                                                 bidirectional_3[0][0]            
__________________________________________________________________________________________________
linear_layer (Dense)            (None, 128)          65664       concatenate_1[0][0]              
__________________________________________________________________________________________________
batchnorm (BatchNormalization)  (None, 128)          512         linear_layer[0][0]               
__________________________________________________________________________________________________
relu_activation (Activation)    (None, 128)          0           batchnorm[0][0]                  
__________________________________________________________________________________________________
dropout (Dropout)               (None, 128)          0           relu_activation[0][0]            
__________________________________________________________________________________________________
output_layer (Dense)            (None, 4)            516         dropout[0][0]                    
==================================================================================================
Total params: 10,645,508
Trainable params: 10,645,252
Non-trainable params: 256
__________________________________________________________________________________________________
Epoch 1/20
learning_rate:  0.010000000000000002
  25/6681 [..............................] - ETA: 55:52 - loss: 3.6215 - acc: 0.67205348/6681 [=======================>......] - ETA: 6:25 - loss: 1.8317 - acc: 0.74446680/6681 [============================>.] - ETA: 0s - loss: 1.6415 - acc: 0.75226681/6681 [==============================] - 1946s 291ms/step - loss: 1.6414 - acc: 0.7522 - val_loss: 0.8318 - val_acc: 0.7699
shuffled
/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py:2379: UserWarning: Layer bidirectional_3 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'bidirectional_1/while/Exit_2:0' shape=(?, 128) dtype=float32>, <tf.Tensor 'bidirectional_1/while/Exit_3:0' shape=(?, 128) dtype=float32>, <tf.Tensor 'bidirectional_1/while_1/Exit_2:0' shape=(?, 128) dtype=float32>, <tf.Tensor 'bidirectional_1/while_1/Exit_3:0' shape=(?, 128) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).
  str(node.arguments) + '. They will not be included '
Epoch 2/20
learning_rate:  0.009140576474687266
 755/6681 [==>...........................] - ETA: 28:07 - loss: 0.7545 - acc: 0.79635836/6681 [=========================>....] - ETA: 4:02 - loss: 0.6588 - acc: 0.80236681/6681 [==============================] - 1939s 290ms/step - loss: 0.6485 - acc: 0.8033 - val_loss: 0.6134 - val_acc: 0.7793
shuffled
Epoch 3/20
learning_rate:  0.006890576474687264
 110/6681 [..............................] - ETA: 31:55 - loss: 0.5336 - acc: 0.83826680/6681 [============================>.] - ETA: 0s - loss: 0.5017 - acc: 0.83686681/6681 [==============================] - 1946s 291ms/step - loss: 0.5017 - acc: 0.8368 - val_loss: 0.5791 - val_acc: 0.7920
shuffled
Epoch 4/20
learning_rate:  0.004109423525312737
 282/6681 [>.............................] - ETA: 30:29 - loss: 0.4429 - acc: 0.85502896/6681 [============>.................] - ETA: 18:09 - loss: 0.4209 - acc: 0.86096680/6681 [============================>.] - ETA: 0s - loss: 0.4063 - acc: 0.86666681/6681 [==============================] - 1951s 292ms/step - loss: 0.4063 - acc: 0.8666 - val_loss: 0.4712 - val_acc: 0.8409
shuffled
Epoch 5/20
learning_rate:  0.0018594235253127371
 282/6681 [>.............................] - ETA: 30:31 - loss: 0.3371 - acc: 0.88876680/6681 [============================>.] - ETA: 0s - loss: 0.3305 - acc: 0.89416681/6681 [==============================] - 1949s 292ms/step - loss: 0.3305 - acc: 0.8942 - val_loss: 0.4949 - val_acc: 0.8183
shuffled
Epoch 6/20
learning_rate:  0.010000000000000002
 283/6681 [>.............................] - ETA: 30:48 - loss: 0.4373 - acc: 0.86001932/6681 [=======>......................] - ETA: 22:50 - loss: 0.4514 - acc: 0.85216680/6681 [============================>.] - ETA: 0s - loss: 0.4362 - acc: 0.86006681/6681 [==============================] - 1943s 291ms/step - loss: 0.4363 - acc: 0.8600 - val_loss: 0.5670 - val_acc: 0.7949
shuffled
Epoch 7/20
learning_rate:  0.009140576474687266
 283/6681 [>.............................] - ETA: 30:47 - loss: 0.3783 - acc: 0.88416680/6681 [============================>.] - ETA: 0s - loss: 0.3623 - acc: 0.88666681/6681 [==============================] - 1940s 290ms/step - loss: 0.3623 - acc: 0.8866 - val_loss: 0.4330 - val_acc: 0.8462
shuffled
Epoch 8/20
learning_rate:  0.006890576474687264
 282/6681 [>.............................] - ETA: 31:09 - loss: 0.2814 - acc: 0.91326680/6681 [============================>.] - ETA: 0s - loss: 0.2917 - acc: 0.90926681/6681 [==============================] - 1944s 291ms/step - loss: 0.2917 - acc: 0.9092 - val_loss: 0.4720 - val_acc: 0.8458
shuffled
Epoch 9/20
learning_rate:  0.004109423525312737
 283/6681 [>.............................] - ETA: 30:53 - loss: 0.2370 - acc: 0.93076680/6681 [============================>.] - ETA: 0s - loss: 0.2335 - acc: 0.92776681/6681 [==============================] - 1968s 294ms/step - loss: 0.2335 - acc: 0.9277 - val_loss: 0.4341 - val_acc: 0.8536
shuffled
Epoch 10/20
learning_rate:  0.0018594235253127371
 281/6681 [>.............................] - ETA: 30:49 - loss: 0.2083 - acc: 0.94166680/6681 [============================>.] - ETA: 0s - loss: 0.1850 - acc: 0.94386681/6681 [==============================] - 1979s 296ms/step - loss: 0.1850 - acc: 0.9438 - val_loss: 0.4100 - val_acc: 0.8651
shuffled
Epoch 11/20
learning_rate:  0.010000000000000002
 282/6681 [>.............................] - ETA: 31:08 - loss: 0.2985 - acc: 0.89846680/6681 [============================>.] - ETA: 0s - loss: 0.2830 - acc: 0.91156681/6681 [==============================] - 1962s 294ms/step - loss: 0.2830 - acc: 0.9115 - val_loss: 0.4276 - val_acc: 0.8519
shuffled
Epoch 12/20
learning_rate:  0.009140576474687266
 282/6681 [>.............................] - ETA: 30:30 - loss: 0.2694 - acc: 0.92096680/6681 [============================>.] - ETA: 0s - loss: 0.2449 - acc: 0.92706681/6681 [==============================] - 1941s 291ms/step - loss: 0.2449 - acc: 0.9270 - val_loss: 0.4687 - val_acc: 0.8445
shuffled
Epoch 13/20
learning_rate:  0.006890576474687264
 282/6681 [>.............................] - ETA: 31:08 - loss: 0.1976 - acc: 0.94183936/6681 [================>.............] - ETA: 13:10 - loss: 0.2050 - acc: 0.93996680/6681 [============================>.] - ETA: 0s - loss: 0.2021 - acc: 0.93986681/6681 [==============================] - 1947s 291ms/step - loss: 0.2020 - acc: 0.9398 - val_loss: 0.4758 - val_acc: 0.8445
shuffled
Epoch 14/20
learning_rate:  0.004109423525312737
 282/6681 [>.............................] - ETA: 30:49 - loss: 0.1616 - acc: 0.95006680/6681 [============================>.] - ETA: 0s - loss: 0.1565 - acc: 0.95336681/6681 [==============================] - 1962s 294ms/step - loss: 0.1565 - acc: 0.9533 - val_loss: 0.4304 - val_acc: 0.8589
shuffled
Epoch 15/20
learning_rate:  0.0018594235253127371
 281/6681 [>.............................] - ETA: 30:30 - loss: 0.1321 - acc: 0.96234301/6681 [==================>...........] - ETA: 11:31 - loss: 0.1269 - acc: 0.96096680/6681 [============================>.] - ETA: 0s - loss: 0.1239 - acc: 0.96226681/6681 [==============================] - 1957s 293ms/step - loss: 0.1239 - acc: 0.9622 - val_loss: 0.4976 - val_acc: 0.8634
shuffled
Epoch 16/20
learning_rate:  0.010000000000000002
 282/6681 [>.............................] - ETA: 31:01 - loss: 0.1758 - acc: 0.94666680/6681 [============================>.] - ETA: 0s - loss: 0.2053 - acc: 0.93956681/6681 [==============================] - 1951s 292ms/step - loss: 0.2053 - acc: 0.9395 - val_loss: 0.4351 - val_acc: 0.8614
shuffled
Epoch 17/20
learning_rate:  0.009140576474687266
 282/6681 [>.............................] - ETA: 30:43 - loss: 0.1831 - acc: 0.94576680/6681 [============================>.] - ETA: 0s - loss: 0.1867 - acc: 0.94626681/6681 [==============================] - 1974s 295ms/step - loss: 0.1867 - acc: 0.9462 - val_loss: 0.4069 - val_acc: 0.8597
shuffled
Epoch 18/20
learning_rate:  0.006890576474687264
 282/6681 [>.............................] - ETA: 31:23 - loss: 0.1694 - acc: 0.95466680/6681 [============================>.] - ETA: 0s - loss: 0.1493 - acc: 0.95696681/6681 [==============================] - 1978s 296ms/step - loss: 0.1493 - acc: 0.9569 - val_loss: 0.4002 - val_acc: 0.8720
shuffled
Epoch 19/20
learning_rate:  0.004109423525312737
 282/6681 [>.............................] - ETA: 31:11 - loss: 0.1328 - acc: 0.96316680/6681 [============================>.] - ETA: 0s - loss: 0.1176 - acc: 0.96616681/6681 [==============================] - 1981s 296ms/step - loss: 0.1176 - acc: 0.9661 - val_loss: 0.4394 - val_acc: 0.8741
shuffled
Epoch 20/20
learning_rate:  0.0018594235253127371
 281/6681 [>.............................] - ETA: 31:05 - loss: 0.0966 - acc: 0.97336680/6681 [============================>.] - ETA: 0s - loss: 0.0930 - acc: 0.97316681/6681 [==============================] - 1988s 298ms/step - loss: 0.0930 - acc: 0.9731 - val_loss: 0.4046 - val_acc: 0.8806
shuffled
6270
6270
0
